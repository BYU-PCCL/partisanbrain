{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import gpt2\n",
    "import neuron_selection\n",
    "reload(gpt2)\n",
    "reload(neuron_selection)\n",
    "from neuron_selection import select_neurons_per_layer\n",
    "from gpt2 import GPT2LMHeadModel\n",
    "from transformers import GPT2Tokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-xl\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2-xl\")\n",
    "model.eval()\n",
    "print(\"\") # To not output the string version of the whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where we decide which neurons to mask\n",
    "with open('middle/neurons_per_layer.json') as file:\n",
    "    neurons_per_layer = json.load(file)\n",
    "\n",
    "neurons_per_layer = {int(k):v for k, v in neurons_per_layer.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons_per_layer = select_neurons_per_layer(n_neurons=1000, method=\"correlation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualitative Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = \"I watched a new movie yesterday. I thought it was\"\n",
    "\n",
    "input = tokenizer.encode(line.strip(), return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model(input, neurons_per_layer=neurons_per_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs = torch.nn.functional.log_softmax(output.logits, dim=2)\n",
    "probs = torch.nn.functional.softmax(output.logits, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = [log_probs[:, i, token_index].item() for i, token_index in enumerate(input.squeeze()[1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "normal_outputs = model.generate(\n",
    "    input,\n",
    "    max_length=30,\n",
    "    do_sample=True,\n",
    "    num_return_sequences=10,\n",
    "    # no_repeat_ngram_size=2,\n",
    "    # repetition_penalty=1.5,\n",
    "    # top_p=0.92,\n",
    "    # temperature=.85,\n",
    "    # do_sample=True,\n",
    "    # top_k=125,\n",
    "    early_stopping=True,\n",
    "    neurons_per_layer=None,\n",
    ")\n",
    "\n",
    "masked_outputs = model.generate(\n",
    "    input,\n",
    "    max_length=30,\n",
    "    do_sample=True,\n",
    "    num_return_sequences=10,\n",
    "    # no_repeat_ngram_size=2,\n",
    "    # repetition_penalty=1.5,\n",
    "    # top_p=0.92,\n",
    "    # temperature=.85,\n",
    "    # do_sample=True,\n",
    "    # top_k=125,\n",
    "    early_stopping=True,\n",
    "    neurons_per_layer=neurons_per_layer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I watched a new movie yesterday. I thought it was funny, but most of it was extremely offensive. For example, this is how I made my\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was a decent way to use \"crowdsourced\" money. Can anyone give me a better\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was pretty good. You have to understand he's never won an Oscar before, never even really heard\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was OK. I thought it was OK on many dimensions.\"\n",
      "\n",
      "The movie is about a boy\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was hilarious. I'm so glad I got to live in the 1800s and that my ancestors weren\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was \"The Hobbit.\"\n",
      "\n",
      "\n",
      "When I was little, my dad would often sit in the room\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was one of the best movies I'd seen all year, but I would have known that within a\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was an outstanding production, much better than the James Bond movies. I knew that the person portrayed was\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was okay, as we all do, but it got a little too serious. It started with a\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was \"Etiquette.\" The female lead is a \"sexpot,\" and everyone in the theater\n",
      "===============================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for output in normal_outputs:\n",
    "    text = tokenizer.decode(output, skip_special_tokens=True)\n",
    "    print(text, end='\\n')\n",
    "    print(143*'=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I watched a new movie yesterday. I thought it was a great little tale called 'Good Night, and Good Luck', written by Alan Trilling.\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was a disaster. At the end, the story came back to me.\n",
      "\n",
      "It came back\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was going to be great but it was awful so stupid and I thought it was so terrible that it\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was good! I'm so sick of TV though. It was my first time watching my TV and\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was an insult to her in my mind to take any moment away from her. I don't think\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was going to be some kind of Disney princess flick from a girl, but instead it was a movie\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was the best I have seen in many years. My review to this day is that it is the\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was so-so. I haven't watched it yet,\" he replied.\n",
      "\n",
      "\"It is\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was wonderful, even if I did feel that at the end of the movie the story was kind of\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was amazing. It was about a girl called Masha. My friend said it was very boring.\n",
      "===============================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for output in masked_outputs:\n",
    "    text = tokenizer.decode(output, skip_special_tokens=True)\n",
    "    print(text, end='\\n')\n",
    "    print(143*'=')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wasserstein Distance of Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wasserstein_distance\n",
    "from scipy.special import kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = \"The tiger licked its lips menacingly as it approached me. I felt\"\n",
    "\n",
    "input = tokenizer.encode(line.strip(), return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_probs = torch.nn.functional.softmax(output.logits, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "filename = \"data/train_data_binary.csv\"\n",
    "\n",
    "df = pd.read_csv(filename)\n",
    "neg_df = df[df.label == 0]\n",
    "pos_df = df[df.label == 1]\n",
    "\n",
    "neg_log_probs = []\n",
    "\n",
    "for i, row in neg_df.iterrows():\n",
    "    if i == 6: \n",
    "        break\n",
    "    else:\n",
    "        print(i)\n",
    "    input = tokenizer.encode(row.sentence.strip(), return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        output = model(input)\n",
    "    log_probs = torch.nn.functional.softmax(output.logits, dim=0)\n",
    "    neg_log_probs.append(log_probs.detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 15, 50257)\n",
      "(1, 42, 50257)\n"
     ]
    }
   ],
   "source": [
    "for neg_log_prob in neg_log_probs:\n",
    "    print(neg_log_prob.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"test.npz\", *neg_log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.load('test.npz')\n",
    "data = [test[key] for key in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 15, 50257)\n",
      "(1, 42, 50257)\n"
     ]
    }
   ],
   "source": [
    "for neg_log_prob in data:\n",
    "    print(neg_log_prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4a98802ec3539a30fc29b6a5501d564d55ef8c2c667ad2e6cc264c7a3fdf048"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('pccl': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
