{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import gpt2\n",
    "import neuron_selection\n",
    "reload(gpt2)\n",
    "reload(neuron_selection)\n",
    "from neuron_selection import select_neurons_per_layer\n",
    "from gpt2 import GPT2LMHeadModel\n",
    "from transformers import GPT2Tokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-xl\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2-xl\")\n",
    "model.eval()\n",
    "print(\"\") # To not output the string version of the whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where we decide which neurons to mask\n",
    "with open('middle/neurons_per_layer.json') as file:\n",
    "    neurons_per_layer = json.load(file)\n",
    "\n",
    "neurons_per_layer = {int(k):v for k, v in neurons_per_layer.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons_per_layer = select_neurons_per_layer(n_neurons=1000, method=\"correlation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualitative Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = \"I watched a new movie yesterday. I thought it was\"\n",
    "\n",
    "input = tokenizer.encode(line.strip(), return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model(input, neurons_per_layer=neurons_per_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs = torch.nn.functional.log_softmax(output.logits, dim=2)\n",
    "probs = torch.nn.functional.softmax(output.logits, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = [log_probs[:, i, token_index].item() for i, token_index in enumerate(input.squeeze()[1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "normal_outputs = model.generate(\n",
    "    input,\n",
    "    max_length=30,\n",
    "    do_sample=True,\n",
    "    num_return_sequences=10,\n",
    "    # no_repeat_ngram_size=2,\n",
    "    # repetition_penalty=1.5,\n",
    "    # top_p=0.92,\n",
    "    # temperature=.85,\n",
    "    # do_sample=True,\n",
    "    # top_k=125,\n",
    "    early_stopping=True,\n",
    "    neurons_per_layer=None,\n",
    ")\n",
    "\n",
    "masked_outputs = model.generate(\n",
    "    input,\n",
    "    max_length=30,\n",
    "    do_sample=True,\n",
    "    num_return_sequences=10,\n",
    "    # no_repeat_ngram_size=2,\n",
    "    # repetition_penalty=1.5,\n",
    "    # top_p=0.92,\n",
    "    # temperature=.85,\n",
    "    # do_sample=True,\n",
    "    # top_k=125,\n",
    "    early_stopping=True,\n",
    "    neurons_per_layer=neurons_per_layer,\n",
    "    force_emotion=\"negative\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I watched a new movie yesterday. I thought it was a total trainwreck (read: boring, cliché, predictable). I did not care that I\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was the best movie ever made. It was a very good movie. I thought it had a lot\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was pretty good. My friends and I were sitting there, and this one woman is crying because,\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was pretty great!\n",
      "\n",
      "What's the most common reaction of someone who has seen the show?\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was good. But there was no way to know without seeing it before writing this. When I said\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was really good, but I don't think it would have been released if I hadn't been aware\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was really funny. I don't think I've ever seen that many kids getting it for free!\"\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was really cool. It was called 'The Imitation Game'. I didn't know that was by\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was so boring, because it took place in some cave and there were no animals or people to distract\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was terrible. I thought it was too dark for kids and it was just a stupid movie.\n",
      "\n",
      "===============================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for output in normal_outputs:\n",
    "    text = tokenizer.decode(output, skip_special_tokens=True)\n",
    "    print(text, end='\\n')\n",
    "    print(143*'=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I watched a new movie yesterday. I thought it was called \"Sneaky Peppers\" and it is really good. It is, of course\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was awesome. The characters were good. It had a cute little romantic subplot, that kind of\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was funny. I thought it was interesting. I thought it was cool.\"\n",
      "\n",
      "After watching two\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was amazing. Now I've lost an entire week to the same movie. And you can't say\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was quite good.'\n",
      "\n",
      "\n",
      "There is some kind of agreement between my mother, my mother's sister\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was great. I loved it.\n",
      "\n",
      "\"My opinion is that in order to win if you\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was all over. This was like that movie, but this scene…this is really cool. Can\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was so cool.\n",
      "\n",
      "I listened to a new song. I thought it was so cool.\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was the sexiest movie yet. I am not a little man, but a little girl watching it\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was pretty good, actually. I was looking for a quick burst of humor and I felt like there\n",
      "===============================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for output in masked_outputs:\n",
    "    text = tokenizer.decode(output, skip_special_tokens=True)\n",
    "    print(text, end='\\n')\n",
    "    print(143*'=')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wasserstein Distance of Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wasserstein_distance\n",
    "from scipy.special import kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = \"The tiger licked its lips menacingly as it approached me. I felt\"\n",
    "\n",
    "input = tokenizer.encode(line.strip(), return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_probs = torch.nn.functional.softmax(output.logits, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "filename = \"data/train_data_binary.csv\"\n",
    "\n",
    "df = pd.read_csv(filename)\n",
    "neg_df = df[df.label == 0]\n",
    "pos_df = df[df.label == 1]\n",
    "\n",
    "neg_log_probs = []\n",
    "\n",
    "for i, row in neg_df.iterrows():\n",
    "    if i == 6: \n",
    "        break\n",
    "    else:\n",
    "        print(i)\n",
    "    input = tokenizer.encode(row.sentence.strip(), return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        output = model(input)\n",
    "    log_probs = torch.nn.functional.softmax(output.logits, dim=0)\n",
    "    neg_log_probs.append(log_probs.detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 15, 50257)\n",
      "(1, 42, 50257)\n"
     ]
    }
   ],
   "source": [
    "for neg_log_prob in neg_log_probs:\n",
    "    print(neg_log_prob.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"test.npz\", *neg_log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.load('test.npz')\n",
    "data = [test[key] for key in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 15, 50257)\n",
      "(1, 42, 50257)\n"
     ]
    }
   ],
   "source": [
    "for neg_log_prob in data:\n",
    "    print(neg_log_prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4a98802ec3539a30fc29b6a5501d564d55ef8c2c667ad2e6cc264c7a3fdf048"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('pccl': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
