{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import gpt2\n",
    "import neuron_selection\n",
    "reload(gpt2)\n",
    "reload(neuron_selection)\n",
    "from neuron_selection import select_neurons_per_layer\n",
    "from gpt2 import GPT2LMHeadModel\n",
    "from transformers import GPT2Tokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-xl\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2-xl\")\n",
    "model.eval()\n",
    "print(\"\") # To not output the string version of the whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons_per_layer = select_neurons_per_layer(n_neurons=1000, method=\"correlation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualitative Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = \"I watched a new movie yesterday. I thought it was\"\n",
    "\n",
    "input = tokenizer.encode(line.strip(), return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "normal_outputs = model.generate(\n",
    "    input,\n",
    "    max_length=30,\n",
    "    do_sample=True,\n",
    "    num_return_sequences=10,\n",
    "    early_stopping=True,\n",
    "    neurons_per_layer=None,\n",
    ")\n",
    "\n",
    "masked_outputs = model.generate(\n",
    "    input,\n",
    "    max_length=30,\n",
    "    do_sample=True,\n",
    "    num_return_sequences=10,\n",
    "    early_stopping=True,\n",
    "    neurons_per_layer=neurons_per_layer,\n",
    "    force_emotion=\"negative\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I watched a new movie yesterday. I thought it was a really clever movie. It had a lot of smart concepts about humanity and a really nice idea\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was just an hour of random comedy. A lot of it got funny. A lot of it was\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was a great action flick.\n",
      "\n",
      "On another day, I watched the game and had to ask\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was interesting: \"The Last Samurai,\" which is about the way Japan, circa the 1700s,\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was fascinating. And what struck me that night were the many parallels between the stories that were being told\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was really excellent. I did not like it, but I did like it a lot. There is\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was going to be an incredibly bad movie. I couldn't believe I'd get to watch it again\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was good enough to post. \n",
      "Now for the meat of this review. \n",
      "Moz\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was really good, really funny. The movie was called Bait and Switch.   I saw it\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was wonderful! The way he played a character and carried himself in it was just brilliant. Really enjoyed\n",
      "===============================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for output in normal_outputs:\n",
    "    text = tokenizer.decode(output, skip_special_tokens=True)\n",
    "    print(text, end='\\n')\n",
    "    print(143*'=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I watched a new movie yesterday. I thought it was stupid, did I. Or even didn't that, I was the- I said, then\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was anyway a boring and stupid, instead of I-me-and-c'-but-\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was all pointless and I probably made my own, even made no-hser--t.\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was not even basic. It was ridiculous. And they turned down eight, six, and even two\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was made that it was any, they were they didn-b. I. I, I.\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was the. Yes, I said as much. That's why I do it. Yes, I\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was totally useless. There were only little, pointless facts anyway.\n",
      ", I must say. At\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was a little weird, because there are no giant giant heroes (no, make I-n-\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was a bit ridiculous.\n",
      ": You have instead of: instead of. That's as much has\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was fucking pointless. It was also boring. Is there any moral reasons why you were running out\n",
      "===============================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for output in masked_outputs:\n",
    "    text = tokenizer.decode(output, skip_special_tokens=True)\n",
    "    print(text, end='\\n')\n",
    "    print(143*'=')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wasserstein Distance of Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wasserstein_distance\n",
    "from scipy.special import kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = \"The tiger licked its lips menacingly as it approached me. I felt\"\n",
    "\n",
    "input = tokenizer.encode(line.strip(), return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_probs = torch.nn.functional.softmax(output.logits, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "filename = \"data/train_data_binary.csv\"\n",
    "\n",
    "df = pd.read_csv(filename)\n",
    "neg_df = df[df.label == 0]\n",
    "pos_df = df[df.label == 1]\n",
    "\n",
    "neg_log_probs = []\n",
    "\n",
    "for i, row in neg_df.iterrows():\n",
    "    if i == 6: \n",
    "        break\n",
    "    else:\n",
    "        print(i)\n",
    "    input = tokenizer.encode(row.sentence.strip(), return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        output = model(input)\n",
    "    log_probs = torch.nn.functional.softmax(output.logits, dim=0)\n",
    "    neg_log_probs.append(log_probs.detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 15, 50257)\n",
      "(1, 42, 50257)\n"
     ]
    }
   ],
   "source": [
    "for neg_log_prob in neg_log_probs:\n",
    "    print(neg_log_prob.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"test.npz\", *neg_log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.load('test.npz')\n",
    "data = [test[key] for key in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 15, 50257)\n",
      "(1, 42, 50257)\n"
     ]
    }
   ],
   "source": [
    "for neg_log_prob in data:\n",
    "    print(neg_log_prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4a98802ec3539a30fc29b6a5501d564d55ef8c2c667ad2e6cc264c7a3fdf048"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('pccl': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
