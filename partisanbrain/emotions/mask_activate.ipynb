{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import gpt2\n",
    "reload(gpt2)\n",
    "from gpt2 import GPT2LMHeadModel\n",
    "from transformers import GPT2Tokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-xl\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2-xl\")\n",
    "model.eval()\n",
    "print(\"\") # To not output the string version of the whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where we decide which neurons to mask\n",
    "with open('middle/neurons_per_layer.json') as file:\n",
    "    neurons_per_layer = json.load(file)\n",
    "\n",
    "neurons_per_layer = {int(k):v for k, v in neurons_per_layer.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualitative Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = \"I watched a new movie yesterday. I thought it was\"\n",
    "\n",
    "input = tokenizer.encode(line.strip(), return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model(input, neurons_per_layer=neurons_per_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs = torch.nn.functional.log_softmax(output.logits, dim=2)\n",
    "probs = torch.nn.functional.softmax(output.logits, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = [log_probs[:, i, token_index].item() for i, token_index in enumerate(input.squeeze()[1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "normal_outputs = model.generate(\n",
    "    input,\n",
    "    max_length=30,\n",
    "    do_sample=True,\n",
    "    num_return_sequences=10,\n",
    "    # no_repeat_ngram_size=2,\n",
    "    # repetition_penalty=1.5,\n",
    "    # top_p=0.92,\n",
    "    # temperature=.85,\n",
    "    # do_sample=True,\n",
    "    # top_k=125,\n",
    "    early_stopping=True,\n",
    "    neurons_per_layer=None,\n",
    ")\n",
    "\n",
    "masked_outputs = model.generate(\n",
    "    input,\n",
    "    max_length=30,\n",
    "    do_sample=True,\n",
    "    num_return_sequences=10,\n",
    "    # no_repeat_ngram_size=2,\n",
    "    # repetition_penalty=1.5,\n",
    "    # top_p=0.92,\n",
    "    # temperature=.85,\n",
    "    # do_sample=True,\n",
    "    # top_k=125,\n",
    "    early_stopping=True,\n",
    "    neurons_per_layer=neurons_per_layer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I watched a new movie yesterday. I thought it was \"I Am Sam\" (which I did not see). This movie, based on the novels\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was interesting, but it wasn't my cup of tea. In fact, I find this movie irritating\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was a pretty good movie. I had the same reaction when I saw the scene where Michael has sex\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was pretty good, but I found it rather dull. I enjoyed the story a lot, but I\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was terrific because people were actually watching that movie again. It has been a year since I've seen\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was great. After watching that movie I feel so happy that I wasn't offended by one thing in\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was just a normal movie until I started to laugh when a scene where two men were arguing over whether\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was kind of a weird movie. I also watched a new anime series for a while. I have\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was cute, the plot was good, and the female protagonist was actually, for lack of a better\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was okay, nothing too special. I loved the plot and the characters involved. Just the normal stuff\n",
      "===============================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for output in normal_outputs:\n",
    "    text = tokenizer.decode(output, skip_special_tokens=True)\n",
    "    print(text, end='\\n')\n",
    "    print(143*'=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I watched a new movie yesterday. I thought it was fantastic. Then I read on the back of the release that it was rated R. I'm\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was funny and that it would be like a funny story. But as I continued through it, I\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was great. It was a totally non-hypefest.\n",
      "\n",
      "When did that happen?\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was boring. I'm not even the type of person who likes horror films. I like \"The\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was cool. But today, I felt a slight change happening. It was almost like I was experiencing\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was great, but the first minute is the best part: It's the guy picking the movie off\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was okay.\n",
      "\n",
      "I guess I'm not as crazy about the new Game of Thrones as people\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was boring. And now, I'm thinking it's really boring. And then I thought I should\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was pretty funny. It had all the usual ingredients: zombies, zombie laaaaaaaaaaaaass\n",
      "===============================================================================================================================================\n",
      "I watched a new movie yesterday. I thought it was pretty awesome.\"\n",
      "\n",
      "\"Not here.\"\n",
      "\n",
      "I knew she wouldn't enjoy this idea\n",
      "===============================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for output in masked_outputs:\n",
    "    text = tokenizer.decode(output, skip_special_tokens=True)\n",
    "    print(text, end='\\n')\n",
    "    print(143*'=')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wasserstein Distance of Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wasserstein_distance\n",
    "from scipy.special import kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = \"The tiger licked its lips menacingly as it approached me. I felt\"\n",
    "\n",
    "input = tokenizer.encode(line.strip(), return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_probs = torch.nn.functional.softmax(output.logits, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "filename = \"data/train_data_binary.csv\"\n",
    "\n",
    "df = pd.read_csv(filename)\n",
    "neg_df = df[df.label == 0]\n",
    "pos_df = df[df.label == 1]\n",
    "\n",
    "neg_log_probs = []\n",
    "\n",
    "for i, row in neg_df.iterrows():\n",
    "    if i == 6: \n",
    "        break\n",
    "    else:\n",
    "        print(i)\n",
    "    input = tokenizer.encode(row.sentence.strip(), return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        output = model(input)\n",
    "    log_probs = torch.nn.functional.softmax(output.logits, dim=0)\n",
    "    neg_log_probs.append(log_probs.detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 15, 50257)\n",
      "(1, 42, 50257)\n"
     ]
    }
   ],
   "source": [
    "for neg_log_prob in neg_log_probs:\n",
    "    print(neg_log_prob.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"test.npz\", *neg_log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.load('test.npz')\n",
    "data = [test[key] for key in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 15, 50257)\n",
      "(1, 42, 50257)\n"
     ]
    }
   ],
   "source": [
    "for neg_log_prob in data:\n",
    "    print(neg_log_prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4a98802ec3539a30fc29b6a5501d564d55ef8c2c667ad2e6cc264c7a3fdf048"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('pccl': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
